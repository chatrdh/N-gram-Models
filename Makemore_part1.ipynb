{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acd4c51-fb8e-4bd0-9d5b-90bb94349da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "words= open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1df681d-4d44-4c3b-a28e-9ad3cdeeb6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "words[:10] #first 10 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1da03e6-7a77-4898-9c1c-5fdaf8da84af",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052665be-ab2d-4ff3-a391-0622225d9892",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(len(w) for w in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e23a87-f839-49b8-9c8e-23e3d78d1d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(len(w) for w in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a4568d-1f86-4cc0-927c-31566574b98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b={}\n",
    "\n",
    "for w in words[:3]: #here we are making tuples of adjacent words using zip\n",
    "     chs=['<S>']+list(w)+['<E>'] #adding a starting and ending character\n",
    "     for ch1,ch2 in zip(chs,chs[1:]):\n",
    "         bigram=(ch1,ch2)\n",
    "         b[bigram]=b.get(bigram,0)+1 #get the count and add 1. '0' is used as default if the tuple is not present in the dict\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98147046-8202-444f-9466-af462c34ec0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15b8f9e-6fc2-490d-a77f-6cb0670499c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(b.items(), key= lambda pair: -pair[1]) #lamda takes a variable pair(tuple:key and value) and uses the neagtive of value to sort "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ad7861-cf50-4810-b35a-6437f1682c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a2064b-208e-434d-99fa-c325e6245641",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=torch.zeros((27,27),dtype=torch.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba40c416-52dd-4c3a-9955-1ffe005438f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars=sorted(list(set(''.join(words))))\n",
    "stoi ={s:i+1 for i,s in enumerate(chars)}  #mapping from characters to numbers\n",
    "stoi['.']=0\n",
    "itos={i:s for s,i in stoi.items()} #mapping from no to characters\n",
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e075e4-1cfe-4d8b-9653-8b651ad23931",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in words: #Now doing it for all words\n",
    "     chs=['.']+list(w)+['.'] #adding a starting and ending character\n",
    "     for ch1,ch2 in zip(chs,chs[1:]):\n",
    "        ix1=stoi[ch1]\n",
    "        ix2=stoi[ch2]\n",
    "        N[ix1,ix2]+=1 #filling the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174541e2-cc3f-4081-8dd6-b647448248ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.imshow(N,cmap='Blues')\n",
    "for i in range(27):\n",
    "    for j in range (27):\n",
    "        chstr=itos[i]+itos[j]\n",
    "        plt.text(j,i,chstr,ha=\"center\",va=\"bottom\",color='gray')\n",
    "        plt.text(j,i,N[i,j].item(),ha=\"center\",va=\"top\",color='gray')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0261365-e9d4-4cf0-ae13-81c27bbfb2ef",
   "metadata": {},
   "source": [
    "### Sampling from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0486b267-57de-412a-895c-2459524fcb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdea452-5932-48a2-aa8e-345e59a187b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "p=N[0].float()\n",
    "p=p/p.sum()\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929d4565-6559-42fb-bfb0-178762634465",
   "metadata": {},
   "outputs": [],
   "source": [
    "g=torch.Generator().manual_seed(2147483647)\n",
    "ix=torch.multinomial(p,num_samples=1,replacement=True,generator=g).item() \n",
    "itos[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f14bcf-984e-46c6-9b69-0527b2934a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "g=torch.Generator().manual_seed(2147483647)\n",
    "p=torch.rand(3,generator=g)\n",
    "p=p/p.sum()\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5021b05-b56f-4c1b-a2b2-8348016f4bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36f3e81-286d-4216-bc1b-7c2790601cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.multinomial(p,num_samples=100,replacement=True,generator=g) #drawing balls from the bag with replacement when the probabilities of diff. balls is given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcbe1ed-8cc9-4c40-a4b9-2b8bdb386e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "P= (N+1).float() #adding for smoothing using add a fake count to avoid infinte loss\n",
    "P/=P.sum(1,keepdim=True) #important for broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f323241-5739-484e-8716-ab4c24be69ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "g=torch.Generator().manual_seed(2147483647)\n",
    "for i in range (20):\n",
    "    ix=0\n",
    "    out=[]\n",
    "    while True:\n",
    "        p=P[ix]\n",
    "       # p=N[ix].float()\n",
    "        #p=p/p.sum()\n",
    "        ix=torch.multinomial(p,num_samples=1,replacement=True,generator=g).item()\n",
    "        out.append(itos[ix])\n",
    "        if ix ==0:\n",
    "         break\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7007a790-e7e0-4f73-b072-a81fa1974159",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maximum Likelihood Estimation\n",
    "log_likelihood=0.0\n",
    "n=0\n",
    "for w in words: \n",
    "     chs=['.']+list(w)+['.'] \n",
    "     for ch1,ch2 in zip(chs,chs[1:]):\n",
    "        ix1=stoi[ch1]\n",
    "        ix2=stoi[ch2]\n",
    "        prob =P[ix1,ix2]\n",
    "        logprob=torch.log(prob)\n",
    "        log_likelihood+=logprob\n",
    "        n+=1\n",
    "#print(f'{ch1}{ch2} : {prob:.4f}')\n",
    "\n",
    "print(f'{log_likelihood =}')\n",
    "nll=-log_likelihood\n",
    "print(f'{nll/n =}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ee9d42-f270-41d9-99c4-6dafcc1d36e6",
   "metadata": {},
   "source": [
    "### The Neural Network Approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6c65db-8fe7-4542-b3fb-d50b71be652f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the training set of biagrams  using just the first example\n",
    "xs=[]\n",
    "ys=[]\n",
    "for w in words[:1]: \n",
    "     chs=['.']+list(w)+['.'] \n",
    "     for ch1,ch2 in zip(chs,chs[1:]):\n",
    "        ix1=stoi[ch1]\n",
    "        ix2=stoi[ch2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "xs=torch.tensor(xs)        \n",
    "ys=torch.tensor(ys)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5e3f79-f054-4997-a6af-5ebe60f9bba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf114e7-cd16-4d99-a089-1abfaf919a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs.shape #the input charater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce53ed94-f101-4468-8d78-82ec0149d716",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7528769e-90f9-466c-a04c-f923c96b7710",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys #the most likely char given the input corresponding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a628317-b200-4022-b853-cbe2a1740fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding\n",
    "import torch.nn.functional as F\n",
    "xenc=F.one_hot(xs,num_classes=27).float()\n",
    "xenc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda483ef-4f47-44ac-914b-60bfae9a7adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "xenc.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89da58a6-cc05-43ba-9b18-1bb4b0aa38a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(xenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f0630f-4bf1-4056-bd33-00a0acd2c87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xenc.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d861a37-0c3d-4d39-a3c1-26603f22a5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "w=torch.rand((27,27),generator=g,requires_grad=True) # 27 neurons\n",
    "xenc @ w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb3829d-c661-4e07-abbd-3b1013756060",
   "metadata": {},
   "outputs": [],
   "source": [
    "(xenc@w).shape # 27 outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3f9757-aa92-4709-8441-3d3d9c4b1fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#these 27 outputs are log(counts) i.e. logits -> exponet them\n",
    "\n",
    "logits=(xenc@w)\n",
    "#softmax\n",
    "counts=(xenc@w).exp()\n",
    "probs = counts/counts.sum(1,keepdims=True) #along columns\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c189d583-ca62-4aa9-ab20-e533a34d1c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610f5840-8adb-49f3-8386-519ccfa8016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88057f5-6c52-4a01-986b-5637b214cd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative log likelihoods (per example)\n",
    "nlls = torch.zeros(5)\n",
    "\n",
    "for i in range(5):\n",
    "    x = xs[i].item()\n",
    "    y = ys[i].item()\n",
    "\n",
    "    print('--------')\n",
    "    print(f'bigram example {i+1}: {itos[x]}{itos[y]} (indexes {x},{y})')\n",
    "    print('input to the neural net:', x)\n",
    "    print('output probabilities from the neural net:', probs[i])\n",
    "    print('label (actual next character):', y)\n",
    "\n",
    "    p = probs[i, y]\n",
    "    print('probability assigned by the net to the correct character:', p.item())\n",
    "\n",
    "    logp = torch.log(p)\n",
    "    print('log likelihood:', logp.item())\n",
    "\n",
    "    nll = -logp\n",
    "    print('negative log likelihood:', nll.item())\n",
    "\n",
    "    nlls[i] = nll\n",
    "\n",
    "print('========')\n",
    "print('average negative log likelihood, i.e. loss =', nlls.mean().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1b74d6-09d3-493b-9f8a-44c367ae24f2",
   "metadata": {},
   "source": [
    "### OPtimization of the Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0b8ed0-dbd4-425e-aaec-cea767510a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b669d9-25a5-4cc4-8485-34b9fd3ef7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938d0197-c197-47d5-a523-35107c639cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly initialize 27 neurons' weights. each neuron receives 27 inputs\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fa9318-aef1-41ff-8ba2-c232d9bcdecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass\n",
    "xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
    "logits = xenc @ W # predict log-counts\n",
    "counts = logits.exp() # counts, equivalent to N\n",
    "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "loss = -probs[torch.arange(5), ys].log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0e6aca-2d71-4f73-a521-0768d4f07cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad29c3e-d689-4484-b2b4-8ca58f4b05e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward pass\n",
    "W.grad = None # set to zero the gradient\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f205e1-b6ab-41ff-a48f-3a2f0e15da43",
   "metadata": {},
   "outputs": [],
   "source": [
    "W.data += -0.1 * W.grad #updating the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961ac519-f6fc-41fa-ba04-4087125a4e40",
   "metadata": {},
   "source": [
    "### Entire Neural Net Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66504ee2-a5b2-4191-976b-b902047b3ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dataset\n",
    "xs, ys = [], []\n",
    "for w in words:\n",
    "  chs = ['.'] + list(w) + ['.']\n",
    "  for ch1, ch2 in zip(chs, chs[1:]):\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    xs.append(ix1)\n",
    "    ys.append(ix2)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print('number of examples: ', num)\n",
    "\n",
    "# initialize the 'network'\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8df65bb-bd14-4f81-a22e-5b38e53e85bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent\n",
    "for k in range(200):\n",
    "  \n",
    "  # forward pass\n",
    "  xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
    "  logits = xenc @ W # predict log-counts\n",
    "  counts = logits.exp() # counts, equivalent to N\n",
    "  probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "  loss = -probs[torch.arange(num), ys].log().mean() + 0.01*(W**2).mean()\n",
    "  print(loss.item())\n",
    "  \n",
    "  # backward pass\n",
    "  W.grad = None # set to zero the gradient\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  W.data += -50 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75c11ad-c4a9-4e89-97cd-bb2c27b54f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling from the neural net model\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "  \n",
    "  out = []\n",
    "  ix = 0\n",
    "  while True:\n",
    "    \n",
    "    # ----------\n",
    "    # BEFORE:\n",
    "    #p = P[ix]\n",
    "    # ----------\n",
    "    # NOW:\n",
    "    xenc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
    "    logits = xenc @ W # predict log-counts\n",
    "    counts = logits.exp() # counts, equivalent to N\n",
    "    p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "    # ----------\n",
    "    \n",
    "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "    out.append(itos[ix])\n",
    "    if ix == 0:\n",
    "      break\n",
    "  print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1152698b-3afc-49d5-814e-758e0fc6608d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
